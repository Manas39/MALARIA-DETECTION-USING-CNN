{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83c56cea-1d92-4d4e-b503-bfcf090fa83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d81679f-9fbf-4a36-beca-f816631a8b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import img_to_array,load_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import cv2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8228ff65-ece6-4bc6-b171-ba153ecacbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices=tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"no of gpus\",len(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db260e48-122f-4b78-8ac2-cfbfbce2dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print('default gpu device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"no gpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c251f2-987d-41e1-81d7-aae6667e8e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"cell_images\"\n",
    "\n",
    "# Initialize lists to store images and labels\n",
    "x = []  # List to store images\n",
    "y = []  # List to store corresponding labels\n",
    "\n",
    "# Define label mapping\n",
    "label_map = {\"Parasitized\": 0, \"Uninfected\": 1}\n",
    "\n",
    "# Iterate through each class folder\n",
    "for class_folder in os.listdir(dataset_path):\n",
    "    class_path = os.path.join(dataset_path, class_folder)\n",
    "\n",
    "    # Iterate through each image in the class folder\n",
    "    for image_filename in os.listdir(class_path):\n",
    "        image_path = os.path.join(class_path, image_filename)\n",
    "\n",
    "        # Read and preprocess the image (you may need to adjust the preprocessing)\n",
    "        image = cv2.imread(image_path)\n",
    "        # Add additional preprocessing steps if needed\n",
    "        # ...\n",
    "\n",
    "        # Append the preprocessed image to the x list\n",
    "        x.append(image)\n",
    "\n",
    "        # Assign the corresponding label based on the class folder\n",
    "        label = label_map[class_folder]\n",
    "        y.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dffb64-fe2e-4cbb-9ff2-b50060e31b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"cell_images\"\n",
    "print(os.listdir(path))\n",
    "classes=os.listdir(path)\n",
    "print(len(classes))\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fb6513-ad0a-42b9-a7f6-ac104fc42485",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "\n",
    "for class_folder in classes:\n",
    "    class_path = os.path.join(path, class_folder)\n",
    "    if os.path.isdir(class_path):\n",
    "        class_images = [os.path.join(class_path, img) for img in os.listdir(class_path) if img.endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp'))]\n",
    "        x.extend(class_images)\n",
    "\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfa8c10-7d5a-48a9-9605-455e70686362",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined=list(zip(x,y))\n",
    "print(combined[:10],\"\\n\")\n",
    "random.shuffle(combined)\n",
    "\n",
    "print(combined[:10],\"\\n\")\n",
    "x[:],y[:] = zip(*combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e8294-e81d-4616-b6a5-64207b4c7ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "for counter, i in enumerate(random.sample(range(0,len(x)) ,9)):\n",
    "   plt.subplot(3,3,counter+1)\n",
    "   plt.subplots_adjust(hspace=0.3)\n",
    "   filename=x[i]\n",
    "   image=imread(filename)\n",
    "   plt.imshow(image)\n",
    "   plt.title(y[i],fontsize=12)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ac8149-7c5a-4672-be09-6d994957e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num=os.listdir(dataset_path)\n",
    "print(len(class_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f29429-aced-4ec2-9368-6a92329711fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "le.fit(y)\n",
    "y_ohe=to_categorical(le.transform(y),len(class_num))\n",
    "print(y_ohe.shape)\n",
    "y_ohe=np.array(y_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0513a8a9-ec41-4a72-b6d4-5b691541950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data=np.array([img_to_array(load_img(img,target_size=(70,70))) for img in x])\n",
    "print(img_data.shape)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(img_data,y_ohe,test_size=0.2,random_state=2)\n",
    "\n",
    "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=0.2,random_state=2)\n",
    "\n",
    "print('Training Dataset Size',x_train.shape);\n",
    "print('Validation Dataset Size',x_val.shape);\n",
    "print('Test Dataset Size',x_test.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbaaa72-b55d-4e87-8538-ad6debe9eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=30,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow(x_train,y_train,shuffle=False,batch_size=batch_size,seed=1)\n",
    "\n",
    "val_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_generator = val_datagen.flow(x_val,y_val,\n",
    "                                shuffle=False,\n",
    "                                batch_size=batch_size,seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f207c9-feec-4783-861f-f4a2fbf6a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), input_shape=(70, 70, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.18),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.18),\n",
    "\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.18),\n",
    "\n",
    "    Dense(128,activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.18),\n",
    "    Dense(2,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae03fe9-e228-4014-b1c9-49390e586c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2960f032-96b7-458e-942f-8d1af3a05daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9f6d1f-9c8f-4261-89db-1a0d7dace7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d09d4a-8808-4048-9f2e-0289b152f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps_per_epoch=x_train.shape[0]//batch_size\n",
    "val_steps_per_epoch=x_val.shape[0]//batch_size\n",
    "history=model.fit(train_generator,steps_per_epoch=train_steps_per_epoch,validation_data=val_generator,validation_steps=val_steps_per_epoch,epochs=30,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4f47a4-1b69-4bf5-ab8d-1d1cb71adb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1=x_test/255\n",
    "test_predictions=model.predict(x_test1)\n",
    "predictions=le.classes_[np.argmax(test_predictions,axis=1)]\n",
    "target_labels=le.classes_[np.argmax(y_test,axis=1)]\n",
    "predict_df=pd.DataFrame({'Target_labels':target_labels,'Predictions':predictions})\n",
    "predict_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efc65aa-7776-4a57-a3ac-0e9dd30f91b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct=(target_labels==predictions)\n",
    "accuracy=correct.sum()/correct.size\n",
    "print(accuracy)\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# y_true is the true labels, y_pred is the predicted labels\n",
    "# both y_true and y_pred should be arrays of integers representing the class labels\n",
    "precision, recall, f1, support = precision_recall_fscore_support(target_labels, predictions, average='macro')\n",
    "\n",
    "print(\"Precision: {:.2f}\".format(precision))\n",
    "print(\"Recall: {:.2f}\".format(recall))\n",
    "print(\"F1 Score: {:.2f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de151165-208d-41b7-af5d-dd6c13de2a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(target_labels, predictions)\n",
    "\n",
    "# Display the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, square=True)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7bb586-2ae9-4c64-aa47-2e680c10c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d983164-2e84-4ea4-8ce6-d1c6efa34ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b774740-4b1c-4836-ad23-8c52d390d0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot\n",
      "  Downloading pydot-2.0.0-py3-none-any.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\paude\\miniconda3\\envs\\malaria\\lib\\site-packages (from pydot) (3.1.1)\n",
      "Downloading pydot-2.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f173c9-5b0d-4498-9382-a081a11d65c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Malaria",
   "language": "python",
   "name": "malaria"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
